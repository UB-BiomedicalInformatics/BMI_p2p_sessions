{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "###  Regression is a method of predicting a response/dependent/target value based on predictors/independent/features.  Regression techniques primarily differ based the type of relationship between the independent and dependent variables.\n",
    "\n",
    "#### Examples:\n",
    "Linear Regression: the response (y) is continuous\n",
    "\n",
    "Logistic Regression: the response (y) is categorical\n",
    "\n",
    "For all models, the predictors (x) can be binary (2 categories), ordinal, continuous, count, or categorical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Regression](https://cdn-images-1.medium.com/max/1600/0*szXvH1a4ZQytyqhg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Equation:\n",
    "\n",
    "$y=\\beta_0+\\beta_1x_1+\\beta_2x_2...+\\beta_px_p+\\epsilon$\n",
    "\n",
    "where $\\epsilon \\sim N(0, \\sigma^2)$\n",
    "\n",
    "What do we want to do? Find the best values for our $\\beta_0...\\beta_p$.\n",
    "\n",
    "How do we do that? minimize the error between the predicted value and the actual value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Predict the level of prostate-specific antigen using clinical measures in men who were about to receive a radical prostectomy.\n",
    "\n",
    "#### Data:\n",
    "\n",
    "A data frame with 97 observations on the following 10 variables.\n",
    "\n",
    "lcavol: log cancer volume  \n",
    "lweight: log prostate weight  \n",
    "age: in years  \n",
    "lbph: log of the amount of benign prostatic hyperplasia  \n",
    "svi: seminal vesicle invasion  \n",
    "lcp: log of capsular penetration  \n",
    "gleason: a numeric vector  \n",
    "pgg45: percent of Gleason score 4 or 5  \n",
    "lpsa: response (y)  \n",
    "train: logical vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's load the data! The data can be downloaded from the Elementary Statistical Learning packages\n",
    "#install.packages(\"ElemStatLearn\") ### note: if you have not installed this packages, you must remove the # at the front of this line\n",
    "library(ElemStatLearn)\n",
    "\n",
    "data(prostate)\n",
    "names(prostate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To fit a model and test it, you need to split the data into training, validation (to tune hyperparameters), and test sets.\n",
    "\n",
    "#### Training Dataset: The sample of data used to fit the model.\n",
    "\n",
    "#### Validation Dataset: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters.\n",
    "\n",
    "#### Test Dataset: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
    "\n",
    "#### What is cross-validation? \n",
    "The goal of cross-validation is to test the modelâ€™s ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset. You use your training set to generate multiple splits and perform the analysis on one subset (called the training set) and validate the analysis on the other subset (validation set).  The most popular is k-fold cross validation.\n",
    "\n",
    "![Image of Split](https://cdn-images-1.medium.com/max/1600/1*Nv2NNALuokZEcV6hYEHdGA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since we do not have any hyperparamters to tune, let's split the data into trainig and test sets!\n",
    "\n",
    "train <- subset(prostate,train==TRUE)[,1:9]\n",
    "test <- subset(prostate,train==FALSE)[,1:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(train)\n",
    "nrow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the data\n",
    "\n",
    "pairs( prostate[,1:9], col=\"blue\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's fit our model using the training data\n",
    "\n",
    "fit1 <- lm(lpsa ~ ., data = train)\n",
    "summary(fit1)\n",
    "# lcavol and lweight are highly significant\n",
    "\n",
    "\n",
    "# Compute 95% confidence interval\n",
    "confint(fit1,level=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How well does our model do when we generalize it to an independent test set?\n",
    "\n",
    "# Prediction\n",
    "prediction1 <- predict(fit1, newdata = test[,1:8])\n",
    "predict(fit1, newdata = test[,1:8], interval = \"confidence\", level=0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember that we wanted to minimize error.  What is our training error? What is our testing error?\n",
    "\n",
    "Training Error: $\\frac{1}{n_{train}} \\sum(y_{train}-x_{train}(b_{train})^2$\n",
    "Test Error: $\\frac{1}{n_{test}} \\sum(y_{test}-x_{test}(b_{test})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training error\n",
    "mean(fit1$residuals^2)\n",
    "# Calculate the prediction error\n",
    "mean((prediction1-test[,9])^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we do better? What is the bias-variance trade-off in linear regression?\n",
    "#### The bias is the difference between the true population parameter and the expected estimator.\n",
    "#### Variance, on the other hand, measures the spread, or uncertainty, in these estimates.\n",
    "\n",
    "We want both the bias and the variance to be low (large values result in poor predictions from the model). Model's error can be decomposed into three parts: error resulting from a large variance, error resulting from significant bias, and the unexplainable part.\n",
    "![Image of Split](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543418451/bias_vs_variance_swxhxx.jpg)\n",
    "\n",
    "* OLS can have a huge variance when there are many predictors (high-dimensionality) or when the predictors are highly correlated with each other (both common problems in medical and clinical data!!!)\n",
    "\n",
    "* Solution: reduce variance at the cost of introducing some bias--we can do this by regularization methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regularization: keeps all variables in the model, but penalizes variables that increase variance\n",
    "![Image of Regression](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543418449/eq7_ylxudw.png)\n",
    "\n",
    "Setting $\\lambda$ to 0 is the same as using the OLS, while the larger its value, the stronger the coefficients' size penalized.  As $\\lambda$ becomes larger, the variance decreases, and the bias increases.\n",
    "\n",
    "#### Ridge works well if there are many large parameters of about the same value\n",
    "\n",
    "How do you choose the hyperparameter $\\lambda$?  cross-validation or seperate validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's use cross-validation!\n",
    "#install.packages(\"glmnet\")\n",
    "library(glmnet)  \n",
    "# Perform 5-fold cross-validation to select lambda ---------------------------\n",
    "lambdas_to_try <- 10^seq(-3, 5, length.out = 100)\n",
    "# Setting alpha = 0 implements ridge regression\n",
    "ridge_cv <- cv.glmnet(as.matrix(train[,1:8]), as.vector(train[,9]), alpha = 0, lambda = lambdas_to_try,\n",
    "                      standardize = TRUE, nfolds = 5)  #alpha=0 means ridge regression\n",
    "# Plot cross-validation results\n",
    "plot(ridge_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best cross-validated lambda\n",
    "lambda_cv <- ridge_cv$lambda.min\n",
    "lambda_cv\n",
    "# Fit final model, get its sum of squared residuals, multiple R-squared, and training error\n",
    "model_cv <- glmnet(as.matrix(train[,1:8]), as.vector(train[,9]), alpha = 0, lambda = lambda_cv, standardize = TRUE)\n",
    "coef(model_cv)\n",
    "\n",
    "\n",
    "#since lambda close to 0 should be close to OLS estimates\n",
    "\n",
    "y_hat_cv <- predict(model_cv, as.matrix(train[,1:8]))\n",
    "ssr_cv <- t(as.vector(train[,9]) - y_hat_cv) %*% (as.vector(train[,9]) - y_hat_cv)\n",
    "rsq_ridge_cv <- cor(as.vector(train[,9]), y_hat_cv)^2\n",
    "\n",
    "\n",
    "mean(ssr_cv)\n",
    "rsq_ridge_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test error\n",
    "y_hat_cv <- predict(model_cv, newx=as.matrix(test[,1:8]), type=\"response\")\n",
    "#ssr_cv <- t(as.vector(test[,9]) - y_hat_cv) %*% (as.vector(test[,9]) - y_hat_cv)\n",
    "rsq_ridge_cv <- cor(as.vector(test[,9]), y_hat_cv)^2\n",
    "\n",
    "prediction.errors=mean((y_hat_cv-test[,9])^2) #mean squared error\n",
    "prediction.errors  ## lower than before!\n",
    "ssr_cv\n",
    "#rsq_ridge_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regularization: Unlike ridge regression, which penalizes sum of squared coefficients (L2 penalty), lasso penalizes the sum of their absolute values (L1 penalty). As a result, for high values of $\\lambda$, many coefficients are exactly 0 under lasso.\n",
    "\n",
    "![Image of Lasso](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543418448/eq11_ij4mms.png)\n",
    "\n",
    "#### Lasso performs variable selection!  Lasso tends to do well if there are a small number of significant parameters and the others are close to zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation to select lambda ---------------------------\n",
    "lambdas_to_try <- 10^seq(-3, 5, length.out = 100)\n",
    "# Setting alpha = 0 implements ridge regression\n",
    "lasso_cv <- cv.glmnet(as.matrix(train[,1:8]), as.vector(train[,9]), alpha = 1, lambda = lambdas_to_try,\n",
    "                      standardize = TRUE, nfolds = 5)  #alpha=0 means ridge regression\n",
    "# Plot cross-validation results\n",
    "plot(lasso_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best cross-validated lambda\n",
    "lambda_cv <- lasso_cv$lambda.min\n",
    "lambda_cv\n",
    "# Fit final model, get its sum of squared residuals and multiple R-squared\n",
    "model_cv <- glmnet(as.matrix(train[,1:8]), as.vector(train[,9]), alpha = 1, lambda = lambda_cv, standardize = TRUE)\n",
    "\n",
    "coef(model_cv)\n",
    "\n",
    "\n",
    "y_hat_cv <- predict(model_cv, as.matrix(test[,1:8]))\n",
    "ssr_cv <- t(as.vector(test[,9]) - y_hat_cv) %*% (as.vector(test[,9]) - y_hat_cv)\n",
    "rsq_lasso_cv <- cor(as.vector(test[,9]), y_hat_cv)^2\n",
    "\n",
    "\n",
    "prediction.errors=mean((y_hat_cv-test[,9])^2) \n",
    "prediction.errors  ## lower than before!\n",
    "ssr_cv\n",
    "#rsq_lasso_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at how coefficients shrink\n",
    "res <- glmnet(as.matrix(train[,1:8]), as.vector(train[,9]), alpha = 1, lambda = lambdas_to_try, standardize = FALSE)\n",
    "plot(res, xvar = \"lambda\", col=1:8)\n",
    "legend(\"bottomright\", lwd = 1, col = 1:8, legend = colnames(as.matrix(train[,1:8])), cex = .7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net: combine the penalties of ridge regression and lasso. Minimizes:\n",
    "\n",
    "![Image of elastic](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1543418448/eq12_vh6ilt.png)\n",
    "\n",
    "where $\\alpha$ is the mixing parameter between lasso and ridge.  We now have two parameters to tune-- $\\alpha$ and $\\lambda$  \n",
    "\n",
    "This can be done using R package caret. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All of these methods can be used for logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:anaconda]",
   "language": "R",
   "name": "conda-env-anaconda-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
